{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains plots produced in the validation sections of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "sns.set_style('ticks')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import scipy.stats as stats\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from epimodel import EpidemiologicalParameters, DefaultModel, preprocess_data\n",
    "\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "fp2 = FontProperties(fname=r\"../fonts/Font Awesome 5 Free-Solid-900.otf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_data('../merged_data/data_final_nov.csv', last_day='2020-05-30', smoothing=1)\n",
    "data.mask_reopenings(print_out = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = pickle.load(open(\"traces/final_final_nov.pkl\", \"rb\"))\n",
    "\n",
    "nS, nCMs = trace.CMReduction.shape\n",
    "default_res = np.exp(np.log(trace.CMReduction) + np.random.normal(size=(nS, nCMs)) * trace.CMAlphaScales)\n",
    "default_res_mean = trace.CMReduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_base_dir = \"../server_final_nov2/\"\n",
    "\n",
    "def tag_fname_to_label(tag, fname):    \n",
    "    if tag == \"cases_threshold\":\n",
    "        r = re.search(r\"(cases_t)(\\d*)\", fname)\n",
    "        return r.groups()[1]\n",
    "    \n",
    "    if tag == \"deaths_threshold\":\n",
    "        r = re.search(r\"(deaths_t)(\\d*)\", fname)\n",
    "        return r.groups()[1]\n",
    "    \n",
    "    if tag == \"scaling\":\n",
    "        if \"simple\" in fname:\n",
    "            return \"Random Constant Scaling\"\n",
    "        elif \"variable\" in fname:\n",
    "            return \"Time-Varying Correction\"\n",
    "    \n",
    "    if tag == \"npi_leaveout\":\n",
    "        npi_names = data.CMs\n",
    "        r = re.search(r\"(\\d*)\", fname)[0]\n",
    "        label = f\"{npi_names[int(r[0])]}\"\n",
    "        for npi in r[1:]:\n",
    "            label += f\",\\n{npi_names[int(npi)]}\"\n",
    "            \n",
    "        return label\n",
    "    \n",
    "    if tag == \"growth_noise\":\n",
    "        npi_names = data.CMs\n",
    "        r = re.search(r\"(growth_noise)-(\\d*.\\d*)\", fname)\n",
    "        \n",
    "        return r.groups()[1]\n",
    "    \n",
    "    if tag == \"iceswe\":\n",
    "        return \"Iceland and Sweden Excluded\"\n",
    "            \n",
    "    if tag == \"NPI_prior\":\n",
    "        if \"icl\" in fname:\n",
    "            return \"Flaxman et. al.\"\n",
    "        \n",
    "        if \"half_normal\" in fname:\n",
    "            return \"$\\\\alpha_i \\sim$Half Normal$(0.2^2)$\"\n",
    "        \n",
    "        if \"normal\" in fname and \"0.2\" in fname:\n",
    "            return \"$\\\\alpha_i \\sim$Normal$(0, 0.2^2)$\"\n",
    "        \n",
    "        if \"normal\" in fname and \"10\" in fname:\n",
    "            return \"$\\\\alpha_i \\sim$Normal$(0, 10^2)$\"\n",
    "        \n",
    "    if tag == \"oxcgrt\":\n",
    "        npi_names = ['Mask Wearing', 'Travel Screen/Quarantine', 'Travel Bans', 'Public Transport Limited',\n",
    "                          'Internal Movement Limited', 'Public Information Campaigns', 'Symptomatic Testing']\n",
    "        r = re.search(r\"(\\d*)\", fname)[0]\n",
    "        label = f\"{npi_names[int(r[0])]}\"\n",
    "        for npi in r[1:]:\n",
    "            label += f\",\\n{npi_names[int(npi)]}\"\n",
    "        return label\n",
    "            \n",
    "    if tag == \"R_prior\":\n",
    "        r = re.search(r\"(R_prior-)(\\d*.\\d*)\", fname)\n",
    "        val = r.groups()[1]\n",
    "        return val\n",
    "    \n",
    "    if tag == \"alpha_noise_Scale\":\n",
    "        r = re.search(r\"(alpha_noise-)(\\d*.\\d*)\", fname)\n",
    "        val = r.groups()[1]\n",
    "        return val\n",
    "\n",
    "    if tag == \"region_holdout\":\n",
    "        return fname[:2]\n",
    "    \n",
    "    if tag == \"structural\":\n",
    "        if \"default\" in fname:\n",
    "            return \"Fixed Effects\"\n",
    "        \n",
    "        if \"additive\" in fname:\n",
    "            return \"Additive\"\n",
    "        \n",
    "        if \"cases\" in fname:\n",
    "            return \"Only Case Data\"\n",
    "        \n",
    "        if \"deaths\" in fname:\n",
    "            return \"Only Death Data\"\n",
    "        \n",
    "        if \"noisy\" in fname:\n",
    "            return \"Noisy-R (Fixed Effects)\"\n",
    "        \n",
    "        if \"discrete_renewal\" in fname:\n",
    "            return \"Discrete Renewal$^*$\"\n",
    "        \n",
    "    if tag == \"alpha_noise_scale\":\n",
    "        an = re.search(r\"(alpha_noise-)(\\d*.\\d*)\", fname).groups()[1]\n",
    "        print(an)\n",
    "        return an\n",
    "\n",
    "        \n",
    "    return f\"{tag} - {fname}\"\n",
    "\n",
    "def load_tagged_traces(result_base_dir, tag, extension='-cs.txt'):\n",
    "    path = os.path.join(results_base_dir, tag)\n",
    "    \n",
    "    all_traces = []\n",
    "    for filedir, _, files in os.walk(path):\n",
    "        for f in files:\n",
    "            if extension in f and 'CasesDelay' not in f and 'DeathsDeath' not in f and '_GI_' not in f:\n",
    "                try:\n",
    "                    trace = np.loadtxt(os.path.join(filedir, f))\n",
    "                    all_traces.append([trace, tag_fname_to_label(tag, f)])\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    \n",
    "    return all_traces\n",
    "\n",
    "def search_tagged_traces(result_base_dir, tag, search_key, extension='-cs.txt'):\n",
    "    path = os.path.join(results_base_dir, tag)\n",
    "    \n",
    "    for filedir, _, files in os.walk(path):\n",
    "        for f in files:\n",
    "            if extension in f and search_key in f:\n",
    "                    trace = np.loadtxt(os.path.join(filedir, f))\n",
    "                    label =  tag_fname_to_label(tag, f)\n",
    "                    return (trace, label)\n",
    "    \n",
    "    print('No experiment found')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [*sns.color_palette(\"colorblind\"), *sns.color_palette(\"dark\")]\n",
    "\n",
    "derived_features_comb = [\n",
    " (\"Gatherings limited to 1000\\npeople or less\", [0]),\n",
    " (\"Gatherings limited to 100\\npeople or less\", [0, 1]),\n",
    " (\"Gatherings limited to 10\\npeople or less\", [0, 1, 2]),\n",
    " (\"Some businesses closed\", [3]),\n",
    " (\"Most businesses closed\", [3, 4]),\n",
    " (\"Schools and universities\\nclosed\", [5, 6]),\n",
    " (\"Stay-at-home order\\n(Additional Effect)\", [7]),\n",
    " ]\n",
    "\n",
    "\n",
    "derived_features_uncomb = [ #()\"Healthcare Infection Control\", [0]),\n",
    " (\"Gatherings limited to 1000\\npeople or less\", [0]),\n",
    " (\"Gatherings limited to 100\\npeople or less\", [1]),\n",
    " (\"Gatherings limited to 10\\npeople or less\", [2]),\n",
    " (\"Some businesses closed\", [3]),\n",
    " (\"Most businesses closed\", [4]),\n",
    " (\"Schools and universities\\nclosed\", [5, 6]),\n",
    " (\"Stay-at-home order\\n(with exemptions)\", [7]),\n",
    " ]\n",
    "\n",
    "derived_features = derived_features_comb\n",
    "\n",
    "cols = sns.cubehelix_palette(3, start=0.2, light=0.6, dark=0.1, rot=0.2)\n",
    "cm_plot_style = [\n",
    "            (\"\\uf0c0\", (0.922, 0.564, 0.612)), # ppl\n",
    "            (\"\\uf0c0\", (0.671, 0.290, 0.341)), # ppl\n",
    "            (\"\\uf0c0\", (0.211, 0.086, 0.011)), # ppl\n",
    "            (\"\\uf07a\", (0.316, 0.506, 0.420)), # shop 1\n",
    "            (\"\\uf07a\", (0.082, 0.196, 0.110)), # shop2\n",
    "            (\"\\uf549\", (0.098, 0.364, 0.58)), # school\n",
    "            (\"\\uf19d\", (0.0, 0.22, 0.4)), # university\n",
    "            (\"\\uf965\", (0.803, 0.376, 0)) # home\n",
    "]\n",
    "\n",
    "def produce_ranges(trace):\n",
    "    means = np.mean(trace, axis=0)\n",
    "    med = np.median(trace, axis=0)\n",
    "    li = np.percentile(trace, 2.5, axis=0)\n",
    "    ui = np.percentile(trace, 97.5, axis=0)\n",
    "    lq = np.percentile(trace, 25, axis=0)\n",
    "    uq = np.percentile(trace, 75, axis=0)\n",
    "    return means, med, li, ui, lq, uq\n",
    "\n",
    "def add_trace_to_plot(res, y_off, col, label, alpha, width, size=8, zeros=None):\n",
    "    nS, _ = res.shape\n",
    "    nF = len(derived_features)\n",
    "    derived_samples = np.zeros((nS, nF))\n",
    "\n",
    "    for f_i, (f, prodrows) in enumerate(derived_features):\n",
    "        samples = np.ones(nS)\n",
    "        for r in prodrows:\n",
    "            samples = samples * res[:, r] \n",
    "        derived_samples[:, f_i] = samples\n",
    "\n",
    "    res = derived_samples\n",
    "    res = 100*(1-res)\n",
    "    \n",
    "    if zeros is not None:\n",
    "        for z in zeros:\n",
    "            if z < nF:\n",
    "                res[:, z] = 1e5\n",
    "    \n",
    "    y_vals = -1 * np.arange(nF)\n",
    "    plt.plot([100], [100], color=col, linewidth=1, alpha=alpha, label=label)\n",
    "    mn, med, li, ui, lq, uq = produce_ranges(res)\n",
    "    plt.scatter(med, y_vals+y_off, marker=\"|\", color=col, s=size, alpha=alpha)\n",
    "    for cm in range(nF):\n",
    "        plt.plot([li[cm], ui[cm]], [y_vals[cm]+y_off, y_vals[cm]+y_off], color=col, alpha=alpha*0.25, linewidth=width)\n",
    "        plt.plot([lq[cm], uq[cm]], [y_vals[cm]+y_off, y_vals[cm]+y_off], color=col, alpha=alpha*0.75, linewidth=width)\n",
    "        \n",
    "def add_additive_trace_to_plot(res, y_off, col, label, alpha, width, size=8, zeros=None):\n",
    "    nS, _ = res.shape\n",
    "    nF = len(derived_features)\n",
    "    derived_samples = np.zeros((nS, nF))\n",
    "\n",
    "    for f_i, (f, prodrows) in enumerate(derived_features):\n",
    "        samples = np.zeros(nS)\n",
    "        for r in prodrows:\n",
    "            samples = samples + res[:, r] \n",
    "        derived_samples[:, f_i] = samples\n",
    "\n",
    "    res = derived_samples\n",
    "    res = 100*res\n",
    "    \n",
    "    if zeros is not None:\n",
    "        for z in zeros:\n",
    "            if z < nF:\n",
    "                res[:, z] = 1e5\n",
    "                \n",
    "    print(np.median(derived_samples, axis=0))\n",
    "    \n",
    "    y_vals = -1 * np.arange(nF)\n",
    "    plt.plot([100], [100], color=col, linewidth=1, alpha=alpha, label=label)\n",
    "    mn, med, li, ui, lq, uq = produce_ranges(res)\n",
    "    plt.scatter(med, y_vals+y_off, marker=\"|\", color=col, s=size, alpha=alpha)\n",
    "    for cm in range(nF):\n",
    "        if cm > 7:\n",
    "            plt.plot([li[cm], ui[cm]], [y_vals[cm]+y_off, y_vals[cm]+y_off], color=col, alpha=alpha*0.25*0.25, linewidth=width, linestyle=\"--\")\n",
    "            plt.plot([lq[cm], uq[cm]], [y_vals[cm]+y_off, y_vals[cm]+y_off], color=col, alpha=alpha*0.75*0.25, linewidth=width, linestyle=\"--\")\n",
    "        else:\n",
    "            plt.plot([li[cm], ui[cm]], [y_vals[cm]+y_off, y_vals[cm]+y_off], color=col, alpha=alpha*0.25, linewidth=width)\n",
    "            plt.plot([lq[cm], uq[cm]], [y_vals[cm]+y_off, y_vals[cm]+y_off], color=col, alpha=alpha*0.75, linewidth=width)\n",
    "        \n",
    "        \n",
    "        \n",
    "def setup_large_plot(y_ticks = True, icons = True, xlabel=True):\n",
    "    nF = len(derived_features)\n",
    "    ax = plt.gca()\n",
    "    x_min = -25\n",
    "    x_max = 75\n",
    "    plt.plot([0, 0], [1, -(nF+2)], \"--k\", linewidth=0.5)\n",
    "    \n",
    "#     plt.plot([17.5, 17.5], [1, -(nF+2)], \"--\", linewidth=0.5, color=cols[0])\n",
    "#     plt.plot([35, 35], [1, -(nF+2)], \"--\", linewidth=0.5, color=cols[0])\n",
    "    \n",
    "    xrange = np.array([x_min, x_max])\n",
    "    for height in range(0, nF+2, 2):\n",
    "        plt.fill_between(xrange, -(height-0.5), -(height+0.5), color=\"silver\", alpha=0.5, linewidth=0)\n",
    "    xtick_vals = [-25, 0, 25, 50, 75, 100]\n",
    "    xtick_str = [f\"{x:.0f}%\" for x in xtick_vals]\n",
    "    if y_ticks:\n",
    "        plt.yticks(-np.arange(nF), [f\"{f[0]}\" for f in derived_features], fontsize=8, ha=\"left\")\n",
    "        yax = ax.get_yaxis()\n",
    "        yax.set_tick_params(pad=125)\n",
    "        \n",
    "    else:\n",
    "        plt.yticks([])\n",
    "    x_r = np.abs(x_min - x_max)\n",
    "    plt.xticks(xtick_vals, xtick_str, fontsize=8)\n",
    "    plt.xlim([x_min, x_max])\n",
    "    plt.ylim([-(nF - 0.25), 0.75])\n",
    "    \n",
    "    if icons:\n",
    "        for cm in range(len(derived_features)):\n",
    "            for i, val in enumerate(derived_features[cm][1]):\n",
    "                plt.text(x_min - 7.5 - 8*i, -cm, cm_plot_style[val][0], horizontalalignment='center', verticalalignment='center',\n",
    "                             fontproperties=fp2, fontsize=8, color=cm_plot_style[val][1], zorder=-i, alpha = 1) \n",
    "                \n",
    "    if xlabel:\n",
    "        plt.xlabel(\"Reduction in $R_t$\\nin the context of our data\", fontsize=8)\n",
    "        \n",
    "def setup_larger_plot(y_ticks = True, icons = True, xlabel=True):\n",
    "    nF = len(derived_features)\n",
    "    ax = plt.gca()\n",
    "    x_min = -25\n",
    "    x_max = 75\n",
    "    plt.plot([0, 0], [1, -(nF+2)], \"--k\", linewidth=0.5)\n",
    "#     plt.plot([17.5, 17.5], [1, -(nF+2)], \"--\", linewidth=0.5, color=cols[0])\n",
    "#     plt.plot([35, 35], [1, -(nF+2)], \"--\", linewidth=0.5, color=cols[0])\n",
    "    xrange = np.array([x_min, x_max])\n",
    "    for height in range(0, nF+2, 2):\n",
    "        plt.fill_between(xrange, -(height-0.5), -(height+0.5), color=\"silver\", alpha=0.5, linewidth=0)\n",
    "    xtick_vals = [-25, 0, 25, 50, 75, 100]\n",
    "    xtick_str = [f\"{x:.0f}%\" for x in xtick_vals]\n",
    "    if y_ticks:\n",
    "        plt.yticks(-np.arange(nF), [f\"{f[0]}\" for f in derived_features], fontsize=8, ha=\"left\")\n",
    "        yax = ax.get_yaxis()\n",
    "        yax.set_tick_params(pad=125)\n",
    "        \n",
    "    else:\n",
    "        plt.yticks([])\n",
    "    x_r = np.abs(x_min - x_max)\n",
    "    plt.xticks(xtick_vals, xtick_str, fontsize=8)\n",
    "    plt.xlim([x_min, x_max])\n",
    "    plt.ylim([-(nF - 0.25), 0.75])\n",
    "    \n",
    "    if icons:\n",
    "        for cm in range(len(derived_features)):\n",
    "            for i, val in enumerate(derived_features[cm][1]):\n",
    "                plt.text(x_min - 7.5 - 9*i, -cm, cm_plot_style[val][0], horizontalalignment='center', verticalalignment='center',\n",
    "                             fontproperties=fp2, fontsize=12, color=cm_plot_style[val][1], zorder=-i, alpha = 1) \n",
    "                \n",
    "    if xlabel:\n",
    "        plt.xlabel(\"Reduction in $R_t$\\nin the context of our data\", fontsize=8)\n",
    "    \n",
    "def setup_small_plot(y_ticks = True, icons = True, xlabel=True):\n",
    "    nF = len(derived_features)\n",
    "    ax = plt.gca()\n",
    "    x_min = -25\n",
    "    x_max = 75\n",
    "    plt.plot([0, 0], [1, -(nF+2)], \"--k\", linewidth=0.5)\n",
    "#     plt.plot([17.5, 17.5], [1, -(nF+2)], \"--\", linewidth=0.5, color=cols[0])\n",
    "#     plt.plot([35, 35], [1, -(nF+2)], \"--\", linewidth=0.5, color=cols[0])\n",
    "    xrange = np.array([x_min, x_max])\n",
    "    for height in range(0, nF+2, 2):\n",
    "        plt.fill_between(xrange, -(height-0.5), -(height+0.5), color=\"silver\", alpha=0.5, linewidth=0)\n",
    "    xtick_vals = [0, 50, 100]\n",
    "    xtick_str = [f\"{x:.0f}%\" for x in xtick_vals]\n",
    "    if y_ticks:\n",
    "        plt.yticks(-np.arange(nF), [f\"{f[0]}\" for f in derived_features], fontsize=8, ha=\"left\")\n",
    "        yax = ax.get_yaxis()\n",
    "        yax.set_tick_params(pad=125)\n",
    "        \n",
    "    else:\n",
    "        plt.yticks([])\n",
    "    x_r = np.abs(x_min - x_max)\n",
    "    plt.xticks(xtick_vals, xtick_str, fontsize=8)\n",
    "    plt.xlim([x_min, x_max])\n",
    "    plt.ylim([-(nF - 0.25), 0.75])\n",
    "    \n",
    "    if icons:\n",
    "        for cm in range(len(derived_features)):\n",
    "            for i, val in enumerate(derived_features[cm][1]):\n",
    "                plt.text(x_min - 7.5 - 13*i, -cm, cm_plot_style[val][0], horizontalalignment='center', verticalalignment='center',\n",
    "                             fontproperties=fp2, fontsize=8, color=cm_plot_style[val][1], zorder=-i, alpha = 1) \n",
    "                \n",
    "    if xlabel:\n",
    "        plt.xlabel(\"Reduction in $R_t$\\nin the context of our data\", fontsize=8)\n",
    "        \n",
    "class ResultsObject():\n",
    "    def __init__(self, indx, trace):\n",
    "        self.CMReduction = trace.CMReduction\n",
    "        self.RegionR = trace.RegionR[:, indx]\n",
    "        self.InfectedCases = trace.InfectedCases[:, indx, :]\n",
    "        self.InfectedDeaths = trace.InfectedDeaths[:, indx, :]\n",
    "        self.ExpectedCases = trace.ExpectedCases[:, indx, :]\n",
    "        self.ExpectedDeaths = trace.ExpectedDeaths[:, indx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_trace(trace, derived_features):\n",
    "    nS, _ = trace.shape\n",
    "    nCMs = len(derived_features)\n",
    "    derived_samples = np.zeros((nS, nCMs))\n",
    "\n",
    "    for f_i, (f, prodrows) in enumerate(derived_features):\n",
    "        samples = np.ones(nS)\n",
    "        for r in prodrows:\n",
    "            samples = samples * trace[:, r] \n",
    "        derived_samples[:, f_i] = samples\n",
    "\n",
    "    res = copy.deepcopy(derived_samples)\n",
    "    res = 100*(1-res)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_score(default_res, traces, exclude=None):\n",
    "    default_med = 1 - np.median(default_res, axis=0)\n",
    "    \n",
    "    regression_table = np.zeros((0, 2))\n",
    "    labels_used = []\n",
    "    \n",
    "    for trace, label in traces:\n",
    "        if exclude is not None:\n",
    "            if isinstance(exclude, list):\n",
    "                flags = [e in label for e in exclude]\n",
    "                if any(flags):\n",
    "                    continue\n",
    "            else:\n",
    "                if exclude in label:\n",
    "                    continue\n",
    "        \n",
    "        med = 1 - np.median(trace[:, :9], axis=0)\n",
    "        med = 1 - med if 'Additive' in label else med\n",
    "        \n",
    "        regression_table = np.append(regression_table, np.vstack([default_med, med]).T, axis=0)\n",
    "        labels_used.append(label)\n",
    "    \n",
    "    mask = ~ np.any(np.isnan(regression_table), axis=-1)\n",
    "    _, _, score, _, _ = stats.linregress(regression_table[mask])\n",
    "    \n",
    "    print(f'Produced stored using {[labels_used]}')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_score_sd(default_res, traces, derived_features, exclude=None):\n",
    "    default_med = np.median(combine_trace(default_res, derived_features), axis=0)\n",
    "    \n",
    "    median_values = np.zeros((0, len(default_med)))\n",
    "    median_values = np.append(median_values, default_med.reshape((1, len(derived_features))), axis=0)\n",
    "    labels_used = []\n",
    "    \n",
    "    \n",
    "    for trace, label in traces:\n",
    "        if exclude is not None:\n",
    "            if isinstance(exclude, list):\n",
    "                flags = [e in label for e in exclude]\n",
    "                if any(flags):\n",
    "                    continue\n",
    "            else:\n",
    "                if exclude in label:\n",
    "                    continue\n",
    "        \n",
    "        med = np.median(combine_trace(trace[:, :8], derived_features), axis=0)\n",
    "        median_values = np.append(median_values, med.reshape((1, len(derived_features))), axis=0)\n",
    "        \n",
    "    med_stds = np.nanstd(median_values, axis=0)\n",
    "    print(med_stds)\n",
    "    score = np.mean(med_stds)\n",
    "    print(score)\n",
    "    \n",
    "    print(f'Produced stored using {[labels_used]}')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category 1: Structural Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = load_tagged_traces(results_base_dir, 'structural', '.txt')\n",
    "score = produce_score_sd(default_res, traces, derived_features_comb, ['Only', 'Unknown', 'Additive'])\n",
    "traces = [(trace, label) for trace, label in traces if ('Only' not in label and 'Additive' not in label and 'Unknown' not in label)]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 3), dpi=300)\n",
    "plt.subplot(121)\n",
    "setup_large_plot()\n",
    "y_off = -np.linspace(-0.2, 0.2, len(traces)+1)\n",
    "width = 1\n",
    "for i, (trace, label) in enumerate(traces):\n",
    "    add_trace_to_plot(trace, y_off[i], colors[i], label, 1, width) \n",
    "add_trace_to_plot(default_res_mean, y_off[-1], 'k', \"Default\", 1, width) \n",
    "plt.xlabel(\"Average reduction in $R_t$,\\nin the context of our data\", fontsize=8)\n",
    "\n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper left\", bbox_to_anchor=(0.85, 1.01), fontsize=6, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=8)\n",
    "plt.title(\"Structural Sensitivity: Multiplicative Models\", fontsize=10)\n",
    "\n",
    "plt.subplot(122)\n",
    "setup_large_plot(False, True, True)\n",
    "trace, label = search_tagged_traces(results_base_dir, 'structural', 'additive', '.txt')\n",
    "add_additive_trace_to_plot(trace, 0, colors[0], label, 1, width)\n",
    "plt.title(\"Structural Sensitivity: Additive Model\", fontsize=10)\n",
    "plt.xlabel(\"Average reduction in $R_t$,\\nas a percentage of $R_0$,\\nin the context of our data\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figs/validation/FigureSSA.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category 2: Unobserved Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8.5, 3), dpi=300)\n",
    "\n",
    "plt.subplot(122)\n",
    "setup_large_plot(False, True, True)\n",
    "\n",
    "traces = load_tagged_traces(results_base_dir, \"oxcgrt\")\n",
    "testing_index = [n for _, n in traces].index('Symptomatic Testing')\n",
    "mask_index = [n for _, n in traces].index('Mask Wearing')\n",
    "orig = copy.deepcopy(traces[testing_index][0])\n",
    "traces[testing_index][0] = orig[:, [1, 2, 3, 4, 5, 6, 7, 8]]\n",
    "orig = copy.deepcopy(traces[mask_index][0])\n",
    "traces[mask_index][0] = orig[:, [1, 2, 3, 4, 5, 6, 7, 8]]\n",
    "\n",
    "# score = produce_score(default_res, traces)\n",
    "score = produce_score_sd(default_res, traces, derived_features_comb)\n",
    "\n",
    "y_off = -np.linspace(-0.3, 0.3, len(traces)+1)\n",
    "width = 1\n",
    "for i, (trace, label) in enumerate(traces):\n",
    "    add_trace_to_plot(trace[:, :9], y_off[i], colors[i], label, 1, width)\n",
    "add_trace_to_plot(default_res, y_off[-1], 'k', \"Default\", 1, width) \n",
    "\n",
    "score = produce_score_sd(default_res, traces, derived_features_comb)\n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper left\", bbox_to_anchor=(0.8, 1.01), fontsize=6, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=8)\n",
    "plt.title(\"Including Additional NPIs\", fontsize=\"10\")\n",
    "\n",
    "plt.subplot(121)\n",
    "derived_features = derived_features_uncomb\n",
    "setup_large_plot(True, True, True)\n",
    "traces = load_tagged_traces(results_base_dir, \"npi_leaveout\")\n",
    "\n",
    "# remove values which are invalid!\n",
    "labels = [l for _, l in traces]\n",
    "for l_i, label in enumerate(labels):\n",
    "    for cm_i, cm in enumerate(data.CMs):\n",
    "        if '<' not in cm and cm in label:\n",
    "            traces[l_i][0][:, cm_i] = np.nan\n",
    "        if cm == label:\n",
    "            traces[l_i][0][:, cm_i] = np.nan\n",
    "        \n",
    "score = produce_score_sd(default_res, traces, derived_features_uncomb)\n",
    "\n",
    "order = [*data.CMs]\n",
    "t_is = [labels.index(o) for o in order]\n",
    "\n",
    "y_off = -np.linspace(-0.3, 0.3, len(traces)+1)\n",
    "width = 1\n",
    "for i, t_i in enumerate(t_is):\n",
    "    trace, label = traces[t_i]\n",
    "    add_trace_to_plot(trace, y_off[i], colors[i], label, 1, width)\n",
    "add_trace_to_plot(default_res, y_off[-1], 'k', \"Default\", 1, width) \n",
    "    \n",
    "derived_features = derived_features_comb\n",
    "\n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper left\", bbox_to_anchor=(0.8, 1.01), fontsize=6, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=8)\n",
    "plt.title(\"Excluding Collected NPIs\\nUncombined Effects Shown\", fontsize=\"10\")\n",
    "plt.tight_layout(w_pad=0)\n",
    "plt.savefig(f\"figs/validation/FigureUOB.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6.75, 3), dpi=300)\n",
    "setup_large_plot()\n",
    "traces = [search_tagged_traces(results_base_dir, 'structural', 'cases'), search_tagged_traces(results_base_dir, 'structural', 'deaths')]\n",
    "score = produce_score(default_res, traces)\n",
    "y_off = -np.linspace(-0.2, 0.2, len(traces)+1)\n",
    "colors_h = [colors[0], colors[3]]\n",
    "width = 2\n",
    "for i, (trace, label) in enumerate(traces):\n",
    "    add_trace_to_plot(trace, y_off[i], colors_h[i], label, 1, width)\n",
    "add_trace_to_plot(default_res, y_off[-1], 'k', \"Default\", 1, width)  \n",
    "\n",
    "score = produce_score_sd(default_res, traces, derived_features_comb)\n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper right\", bbox_to_anchor=(1.55, 1.01), fontsize=6, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=8)\n",
    "plt.title(\"Data Type\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figs/validation/FigureDataType.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10.5, 5.5), dpi=300)\n",
    "\n",
    "traces = load_tagged_traces(results_base_dir, 'region_holdout')\n",
    "score = produce_score_sd(default_res, traces, derived_features_comb)\n",
    "\n",
    "y_off = -np.linspace(-0.4, 0.4, 8)\n",
    "for r_i, r in enumerate(data.Rs):\n",
    "    r_i_p = r_i % 7 \n",
    "    if r_i_p == 0:\n",
    "        plt.legend(shadow=True, fancybox=True, loc=\"upper left\", bbox_to_anchor=(0.8, 1.01), fontsize=6, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=8)\n",
    "        plt.subplot(2, 3, int(r_i/7) + 1)\n",
    "        \n",
    "        xlabel = False if (int(r_i/7) + 1) < 4 else True\n",
    "        \n",
    "        if (int(r_i/7) + 1) == 1 or (int(r_i/7) + 1) == 4:\n",
    "            setup_large_plot(xlabel=xlabel)\n",
    "        else:\n",
    "            setup_large_plot(False, xlabel=xlabel)\n",
    "        add_trace_to_plot(default_res, y_off[-1], \"k\", \"Default\", 1, 1)\n",
    "    trace, _ = search_tagged_traces(results_base_dir, 'region_holdout', r)\n",
    "    label = data.RNames[r][0]\n",
    "    if 'and' in label and 'Bosnia' in label:\n",
    "        label = 'Bosnia and\\nHerzegovina'\n",
    "    add_trace_to_plot(trace, y_off[r_i_p], colors[r_i_p], label, 1, 1)\n",
    "    \n",
    "#     plt.legend(shadow=True, fancybox=True, loc=\"upper right\", bbox_to_anchor=(0.8, 1.01), fontsize=8, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=10)\n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper left\", bbox_to_anchor=(0.8, 1.01), fontsize=6, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=8)\n",
    "plt.tight_layout(w_pad=0.15)\n",
    "plt.savefig(f\"figs/validation/FigureCountryLeaveout.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 3), dpi=300)\n",
    "\n",
    "plt.subplot(121)\n",
    "setup_large_plot()\n",
    "\n",
    "traces = load_tagged_traces(results_base_dir, \"cases_threshold\")\n",
    "traces = [(trace, label) for trace, label in traces if '10' not in label]\n",
    "score = produce_score_sd(default_res, traces, derived_features_comb)\n",
    "\n",
    "y_off = -np.linspace(-0.25, 0.25, len(traces)+1)\n",
    "width = 1\n",
    "traces.sort(key= lambda x: int(x[1]))\n",
    "for i, (trace, label) in enumerate(traces):\n",
    "    if i<2:\n",
    "        add_trace_to_plot(trace[:, :9], y_off[i], colors[i], label, 1, width)\n",
    "        \n",
    "    if i == 2:\n",
    "        add_trace_to_plot(default_res, y_off[i], 'k', \"Default (100)\", 1, width)\n",
    "    \n",
    "    if i > 1:\n",
    "        add_trace_to_plot(trace[:, :9], y_off[i+1], colors[i], label, 1, width)\n",
    "\n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper left\", bbox_to_anchor=(0.95, 1.01), fontsize=6, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=8)\n",
    "plt.title(\"Minimum Cases Threshold\", fontsize=\"10\")\n",
    "\n",
    "plt.subplot(122)\n",
    "setup_large_plot(False, True, True)\n",
    "traces = load_tagged_traces(results_base_dir, \"deaths_threshold\")\n",
    "score = produce_score_sd(default_res, traces, derived_features_comb)\n",
    "\n",
    "traces.sort(key= lambda x: int(x[1]))\n",
    "\n",
    "y_off = -np.linspace(-0.25, 0.25, len(traces)+1)\n",
    "width = 1\n",
    "for i, (trace, label) in enumerate(traces):\n",
    "    if i<2:\n",
    "        add_trace_to_plot(trace[:, :9], y_off[i], colors[i], label, 1, width)\n",
    "        \n",
    "    if i == 2:\n",
    "        add_trace_to_plot(default_res, y_off[i], 'k', \"Default (10)\", 1, width)\n",
    "    \n",
    "    if i > 1:\n",
    "        add_trace_to_plot(trace[:, :9], y_off[i+1], colors[i], label, 1, width)\n",
    " \n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper left\", bbox_to_anchor=(0.95, 1.01), fontsize=6, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=8)\n",
    "plt.title(\"Minimum Deaths Threshold\", fontsize=\"10\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figs/validation/FigureThresholds.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# additional epi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 3), dpi=300)\n",
    "\n",
    "plt.subplot(121)\n",
    "setup_large_plot()\n",
    "\n",
    "traces = load_tagged_traces(results_base_dir, \"R_prior\")\n",
    "score = produce_score_sd(default_res, traces, derived_features_comb)\n",
    "\n",
    "y_off = -np.linspace(-0.25, 0.25, len(traces)+1)\n",
    "width = 1\n",
    "traces.sort(key= lambda x: float(x[1]))\n",
    "for i, (trace, label) in enumerate(traces):\n",
    "    if i<2:\n",
    "        add_trace_to_plot(trace[:, :9], y_off[i], colors[i], f'$\\\\mu[R] ={label}$', 1, width)\n",
    "        \n",
    "    if i == 2:\n",
    "        add_trace_to_plot(default_res, y_off[i], 'k', f'Default\\n$\\\\mu[R] =3.28$', 1, width)\n",
    "    \n",
    "    if i > 1:\n",
    "        add_trace_to_plot(trace[:, :9], y_off[i+1], colors[i], f'$\\\\mu[R] ={label}$', 1, width)\n",
    "\n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper left\", bbox_to_anchor=(0.95, 1.01), fontsize=6, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=8)\n",
    "plt.title(\"$R_0$ prior\", fontsize=10)\n",
    "\n",
    "plt.subplot(122)\n",
    "setup_large_plot(False, True, True)\n",
    "traces = load_tagged_traces(results_base_dir, \"NPI_prior\")\n",
    "score = produce_score_sd(default_res, traces, derived_features_comb)\n",
    "\n",
    "# traces.sort(key= lambda x: int(x[1]))\n",
    "\n",
    "y_off = -np.linspace(-0.25, 0.25, len(traces)+1)\n",
    "width = 1\n",
    "for i, (trace, label) in enumerate(traces):\n",
    "    add_trace_to_plot(trace[:, :9], y_off[i], colors[i], label, 1, width)\n",
    "add_trace_to_plot(default_res, y_off[-1], 'k', \"Default\", 1, width) \n",
    "    \n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper left\", bbox_to_anchor=(0.95, 1.01), fontsize=6, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=8)\n",
    "plt.title(\"NPI Effectiveness Prior\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figs/validation/FigureAdditionalEpi.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iceland, Sweden Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3), dpi=300)\n",
    "\n",
    "derived_features = [\n",
    " (\"Schools closed\", [5]),\n",
    " (\"Universities closed\", [6]),\n",
    " (\"Schools and univerisities closed\", [5, 6]),\n",
    " ]\n",
    "\n",
    "nF = len(derived_features)\n",
    "\n",
    "ax = plt.gca()\n",
    "x_min = -25\n",
    "x_max = 100\n",
    "plt.plot([0, 0], [1, -(nF)], \"--k\", linewidth=0.5)\n",
    "xrange = np.array([x_min, x_max])\n",
    "for height in range(0, nF+2, 2):\n",
    "    plt.fill_between(xrange, -(height-0.5), -(height+0.5), color=\"silver\", alpha=0.5, linewidth=0)\n",
    "xtick_vals = [-25, 0, 25, 50, 75, 100]\n",
    "xtick_str = [f\"{x:.0f}%\" for x in xtick_vals]\n",
    "\n",
    "plt.yticks(-np.arange(nF), [f\"{f[0]}\" for f in derived_features], fontsize=8, ha=\"left\")\n",
    "yax = ax.get_yaxis()\n",
    "yax.set_tick_params(pad=150)\n",
    "\n",
    "x_r = np.abs(x_min - x_max)\n",
    "plt.xticks(xtick_vals, xtick_str, fontsize=8)\n",
    "plt.xlim([x_min, x_max])\n",
    "plt.ylim([-(nF - 0.25), 0.75])\n",
    "\n",
    "for cm in range(len(derived_features)):\n",
    "    for i, val in enumerate(derived_features[cm][1]):\n",
    "        plt.text(x_min - 7.5 - 8*i, -cm, cm_plot_style[val][0], horizontalalignment='center', verticalalignment='center',\n",
    "                     fontproperties=fp2, fontsize=8, color=cm_plot_style[val][1], zorder=-i, alpha = 1) \n",
    "\n",
    "plt.xlabel(\"Average reduction in $R_t$,\\nin the context of our data\", fontsize=8)\n",
    "\n",
    "\n",
    "iceland = search_tagged_traces(results_base_dir, 'region_holdout', 'IS')[0]\n",
    "sweden = search_tagged_traces(results_base_dir, 'region_holdout', 'SE')[0]\n",
    "iceswe = search_tagged_traces(results_base_dir, 'iceswe', 'iceswe')[0]\n",
    "y_off = -np.linspace(-0.2, 0.2, 4)\n",
    "add_trace_to_plot(iceland, y_off[0], colors[0], \"Iceland Excluded\", 1, 2)\n",
    "add_trace_to_plot(sweden, y_off[1], colors[1], \"Sweden Excluded\", 1, 2)\n",
    "add_trace_to_plot(iceswe, y_off[2], colors[2], \"Iceland and\\nSweden Excluded\", 1, 2)\n",
    "add_trace_to_plot(default_res, y_off[-1], \"k\", \"Default\", 1, 2)\n",
    "plt.legend(shadow=True, fancybox=True, fontsize=6)\n",
    "plt.title(\"Schools and Universities Sensitivity\", fontsize=10)\n",
    "plt.savefig(f\"figs/validation/FigureISSE.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_features = derived_features_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fname_to_params(fname):\n",
    "    gi = float(re.search(r\"(gi_mean_mean)-(\\d*.\\d*)\", fname).groups()[1])\n",
    "    cd = float(re.search(r\"(cases_mean_mean)-(\\d*.\\d*)\", fname).groups()[1])\n",
    "    dd = float(re.search(r\"(deaths_mean_mean)-(\\d*.\\d*)\", fname).groups()[1])\n",
    "    \n",
    "    return gi, cd, dd\n",
    "\n",
    "def load_tagged_traces_gs(result_base_dir, tag):\n",
    "    path = os.path.join(results_base_dir, tag)\n",
    "    \n",
    "    all_traces = []\n",
    "    for filedir, _, files in os.walk(path):\n",
    "        for f in files:\n",
    "            if '-cs.txt' in f:\n",
    "                try:\n",
    "                    trace = np.loadtxt(os.path.join(filedir, f))\n",
    "                    \n",
    "                    nS, _ = trace.shape\n",
    "                    nF = len(derived_features)\n",
    "                    derived_samples = np.zeros((nS, nF))\n",
    "\n",
    "                    for f_i, (_, prodrows) in enumerate(derived_features):\n",
    "                        samples = np.ones(nS)\n",
    "                        for r in prodrows:\n",
    "                            samples = samples * trace[:, r] \n",
    "                        derived_samples[:, f_i] = samples\n",
    "\n",
    "                    res = derived_samples\n",
    "                    median = np.median(res, axis=0)\n",
    "                    \n",
    "                    gi, cd, dd = fname_to_params(f)\n",
    "                    \n",
    "                    all_traces.append([median, gi, cd, dd, trace])\n",
    "                    print(f'{len(all_traces)} Exps')\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    \n",
    "    return all_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_traces = load_tagged_traces_gs(results_base_dir, 'epiparam_prior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians, gis, cds, dds, full_traces = list(zip(*global_traces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_score_sd(default_res, [(t, '') for t in full_traces], derived_features_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nS, _ = default_res.shape\n",
    "nF = len(derived_features)\n",
    "derived_samples = np.zeros((nS, nF))\n",
    "\n",
    "for f_i, (_, prodrows) in enumerate(derived_features):\n",
    "    samples = np.ones(nS)\n",
    "    for r in prodrows:\n",
    "        samples = samples * default_res[:, r] \n",
    "    derived_samples[:, f_i] = samples\n",
    "    \n",
    "default_median = np.median(derived_samples, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_gis = np.unique(gis)\n",
    "unique_cds = np.unique(cds)\n",
    "unique_dds = np.unique(dds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gi_to_grid(cm, global_traces, unique_cds, unique_dds, gi, default_median):\n",
    "    filtered_traces = list(filter(lambda t: t[1] == gi, global_traces))\n",
    "    \n",
    "    grid = np.zeros((len(unique_cds), len(unique_dds)))\n",
    "    grid[:] = np.nan\n",
    "    \n",
    "    for meds, _, cd, dd, _ in filtered_traces:\n",
    "        cd_ind = np.where(unique_cds == cd)\n",
    "        dd_ind = np.where(unique_dds == dd)\n",
    "        val = 100*(-meds[cm] + default_median[cm]) \n",
    "        grid[cd_ind, dd_ind] = val\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_names = ['Gatherings <1000', 'Gatherings <100', 'Gatherings <10', 'Some Buss', 'Most Buss', 'Educat', 'Stay Home']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "current_cmap = mpl.cm.get_cmap('PuOr_r')\n",
    "current_cmap.set_bad(color='k')\n",
    "\n",
    "plt.figure(figsize=(10, 12), dpi=300)\n",
    "for cm in range(7):\n",
    "    for gi_ind, gi in enumerate(unique_gis.tolist()):\n",
    "        plt.subplot(7, 5, 5*cm + gi_ind + 1)\n",
    "        grid = gi_to_grid(cm, global_traces, unique_cds, unique_dds, gi, default_median)\n",
    "        im = plt.imshow(grid, cmap=current_cmap, origin='lower', vmin=-15, vmax=15)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        if cm == 0:\n",
    "            plt.title(f'$\\\\mu_{{GI}}={gi:.2f}$', fontsize=10)\n",
    "        \n",
    "        if gi_ind == 0:\n",
    "            plt.ylabel(f'$\\\\bf{short_names[cm]}$\\n\\n Infection to Case\\nConfirmation Delay (Days)', fontsize=8)\n",
    "            plt.yticks(np.arange(5), unique_cds, fontsize=6)\n",
    "            \n",
    "        if cm == 6:\n",
    "            plt.xlabel(f'Infection to Death Delay (Days)', fontsize=8)\n",
    "            plt.xticks(np.arange(5), unique_dds, fontsize=6)\n",
    "            \n",
    "        ax = plt.gca()\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        cbr = plt.colorbar(im, cax=cax, format=PercentFormatter())\n",
    "        ax = plt.gca()\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=7)\n",
    "        cbr.set_ticks([-15, -7.5, 0, 7.5, 15])\n",
    "#         cbr.set_label('$\\\\Delta$(Median) Effectivenss\\n Estimate', fontsize=8)\n",
    "        \n",
    "plt.tight_layout(w_pad=0.75, h_pad=-8)\n",
    "plt.savefig(f\"figs/validation/FigureGlobalSAAll.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressed Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_traces(filter_lambda, global_traces):\n",
    "    filtered_traces = list(filter(filter_lambda, global_traces))\n",
    "    \n",
    "    nF = 8\n",
    "    samples = np.zeros((0, nF))\n",
    "    \n",
    "    for _, _, _, _, t in filtered_traces:\n",
    "        samples = np.append(samples, t, axis=0)\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_traces = []\n",
    "for unique_cd in unique_cds:\n",
    "    cd_traces.append((combine_traces(lambda t: t[2] == unique_cd, global_traces), f'Mean {unique_cd} days'))\n",
    "    \n",
    "gi_traces = []\n",
    "for unique_gi in unique_gis:\n",
    "    gi_traces.append((combine_traces(lambda t: t[1] == unique_gi, global_traces), f'Mean {unique_gi} days'))\n",
    "    \n",
    "dd_traces = []\n",
    "for unique_dd in unique_dds:\n",
    "    dd_traces.append((combine_traces(lambda t: t[3] == unique_dd, global_traces), f'Mean {unique_dd} days'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10.25, 3), dpi=300)\n",
    "plt.subplot(131)\n",
    "setup_large_plot()\n",
    "score = produce_score_sd(default_res, cd_traces, derived_features_comb)\n",
    "y_off = -np.linspace(-0.3, 0.3, len(cd_traces))\n",
    "width = 1\n",
    "for i, (trace, label) in enumerate(cd_traces):\n",
    "    add_trace_to_plot(trace, y_off[i], colors[i], label, 1, width)\n",
    "\n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper right\", bbox_to_anchor=(1.35, 1.01), fontsize=6, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=8)\n",
    "plt.title(\"Infection to Case-Confirmation Delay\", fontsize=\"10\")\n",
    "\n",
    "plt.subplot(132)\n",
    "score = produce_score_sd(default_res, dd_traces, derived_features_comb)\n",
    "setup_large_plot(False, True, True)\n",
    "y_off = -np.linspace(-0.3, 0.3, len(dd_traces))\n",
    "width = 1\n",
    "for i, (trace, label) in enumerate(dd_traces):\n",
    "    add_trace_to_plot(trace[:, :9], y_off[i], colors[i], label, 1, width)\n",
    "\n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper right\", bbox_to_anchor=(1.35, 1.01), fontsize=6, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=8)\n",
    "plt.title(\"Infection to Death Delay\", fontsize=\"10\")\n",
    "\n",
    "plt.subplot(133)\n",
    "score = produce_score_sd(default_res, gi_traces, derived_features_comb)\n",
    "setup_large_plot(False, True, True)\n",
    "y_off = -np.linspace(-0.3, 0.3, len(gi_traces))\n",
    "width = 1\n",
    "for i, (trace, label) in enumerate(gi_traces):\n",
    "    add_trace_to_plot(trace[:, :9], y_off[i], colors[i], label, 1, width)\n",
    "\n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper right\", bbox_to_anchor=(1.35, 1.01), fontsize=6, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=8)\n",
    "plt.title(\"Generation Interval\", fontsize=\"10\")\n",
    "\n",
    "plt.tight_layout(w_pad=-2)\n",
    "plt.savefig(f\"figs/validation/FigureEpiparamCompressed.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ascertainment rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5.25, 3), dpi=300)\n",
    "\n",
    "setup_large_plot()\n",
    "\n",
    "traces = load_tagged_traces(results_base_dir, \"scaling\")\n",
    "score = produce_score_sd(default_res, traces, derived_features_comb)\n",
    "\n",
    "derived_features = derived_features_comb\n",
    "\n",
    "width = 1\n",
    "score = produce_score_sd(default_res, traces, derived_features_comb)\n",
    "y_off = -np.linspace(-0.3, 0.3, len(traces)+1)\n",
    "width = 1\n",
    "for i, (trace, label) in enumerate(traces):\n",
    "    add_trace_to_plot(trace, y_off[i], colors[i], label, 1, width)\n",
    "add_trace_to_plot(default_res, y_off[-1], 'k', \"Default\", 1, width) \n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper left\", bbox_to_anchor=(0.95, 1.01), fontsize=6, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=8)\n",
    "plt.title(\"Case Undercounting Correction\", fontsize=\"10\")\n",
    "# plt.subplot(122)\n",
    "# setup_large_plot(False, True, True)\n",
    "\n",
    "# traces = load_tagged_traces(results_base_dir, \"scaling\", '-mean.txt')\n",
    "# score = produce_score_sd(default_res, traces, derived_features_comb)\n",
    "\n",
    "# derived_features = derived_features_comb\n",
    "\n",
    "# width = 1\n",
    "# score = produce_score_sd(default_res, traces, derived_features_comb)\n",
    "# y_off = -np.linspace(-0.3, 0.3, len(traces)+1)\n",
    "# width = 1\n",
    "# traces.reverse()\n",
    "# for i, (trace, label) in enumerate(traces):\n",
    "#     add_trace_to_plot(trace, y_off[i], colors[i], label, 1, width)\n",
    "# add_trace_to_plot(default_res_mean, y_off[-1], 'k', \"Default\", 1, width) \n",
    "\n",
    "# plt.legend(shadow=True, fancybox=True, loc=\"upper left\", bbox_to_anchor=(0.95, 1.01), fontsize=6, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=8)\n",
    "plt.tight_layout(w_pad=0.25)\n",
    "# plt.title(\"Case Undercounting Correction\\nMean Effects\", fontsize=\"10\")\n",
    "plt.savefig(f\"figs/validation/FigureUndercounting.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# alpha noise scale results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5.25, 3), dpi=300)\n",
    "setup_large_plot()\n",
    "traces = load_tagged_traces(results_base_dir, \"alpha_noise_scale\")\n",
    "score = produce_score(default_res, traces)\n",
    "y_off = -np.linspace(-0.3, 0.3, len(traces)+1)\n",
    "width = 1\n",
    "\n",
    "traces.sort(key=lambda t: float(t[1]))\n",
    "for i, (trace, label) in enumerate(traces):\n",
    "    add_trace_to_plot(trace, y_off[i], colors[i], label if label != \"0.04\" else \"Default\\n0.04\", 1, width)\n",
    "\n",
    "score = produce_score_sd(default_res, traces, derived_features_comb)\n",
    "plt.legend(shadow=True, fancybox=True, loc=\"upper right\", bbox_to_anchor=(1.35, 1.01), fontsize=8, title=f'$\\\\bar{{\\\\sigma}}={score:.2f}\\\\%$', title_fontsize=10)\n",
    "plt.title(\"$\\\\sigma_i$ Prior Scale\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figs/validation/FigureAlphaNoises.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
